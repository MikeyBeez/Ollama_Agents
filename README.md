# AI_Functions: Your Personal AI Assistant Builder ğŸ¤–

Welcome to AI_Functions! This repository allows you to create a spectacular AI agent using Ollama. It's like having a LEGO set for AI - mix, match, and build your dream assistant! ğŸ§±âœ¨

## ğŸš€ What's New?

- ğŸ¨ Colorful command-line interface
- ğŸ§  Enhanced memory management
- ğŸ” Integrated DuckDuckGo search capabilities
- ğŸ› ï¸ Improved modular design for easy customization
- ğŸ” Memory search commands: `/ms` and `/msl`
- ğŸ§µ New `/fabric` command for using Fabric patterns
- ğŸ“‚ Refactored command structure for better organization
- ğŸ§ª Comprehensive test suite added

## ğŸŒŸ Key Features

1. ğŸ“š Modular Architecture: Each function is in a separate module, making it easy to add, remove, or modify features.
2. ğŸ’¬ Interactive CLI: Built with `prompt_toolkit` for a sci-fi movie-worthy experience!
3. ğŸ” Secure Configuration: Customize your AI's personality in `config.py`.
4. ğŸ§ª Comprehensive Testing: Because quality is our superpower!
5. ğŸŒ Web Search Integration: Your AI can now search the web using DuckDuckGo.
6. ğŸ“œ Chat History: Never forget a conversation with built-in history management.
7. ğŸ§  Memory Search: Quickly retrieve and utilize relevant information from past interactions and uploaded documents.
8. ğŸ§µ Fabric Integration: Use Fabric patterns for enhanced AI interactions.

## ğŸ› ï¸ Getting Started

### Prerequisites

- Python 3.8 or higher
- Conda (for managing virtual environments)
- Ollama (for running local language models)

### Setting Up the Environment

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/AI_Functions.git
   cd AI_Functions
   ```

2. Create and activate a conda virtual environment:
   ```bash
   conda create -n ai_functions python=3.8
   conda activate ai_functions
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Installing Ollama

1. Visit the [Ollama website](https://ollama.com/) and follow the installation instructions for your operating system.

2. Once installed, run Ollama and download a model (e.g., llama2):
   ```bash
   ollama run llama2
   ```

### Configuration

1. Customize your AI in `config.py`.

2. Set up your API keys and other configurations in a `.env` file (use `.env.example` as a template).

### Running the Application

Run the main script:
```bash
python src/main.py
```

## ğŸ§ª Running Tests

Ensure your AI is in top shape:

```bash
python -m unittest discover src/tests
```

## ğŸ“˜ Module Documentation

- ğŸ›ï¸ [Input Module](docs/input_module.md)
- ğŸ¤– [Ollama Client](docs/ollama_client.md)
- ğŸ§© [Assemble Module](docs/assemble_module.md)
- ğŸ¨ [Banner Module](docs/banner_module.md)
- ğŸ” [DuckDuckGo Search](docs/ddg_search_module.md)

## ğŸ” Memory Search Commands

- `/ms n m query`: Search memories and process query (short version, only shows answer)
- `/msl n m query`: Search memories and process query (long version, shows memories and answer)
  - `n`: Number of top results to retrieve
  - `m`: Minimum similarity threshold (0-1)
  - `query`: Your question or prompt
  Example: `/ms 5 0.7 Who was Alan Turing?`

## ğŸ§µ Fabric Command

Use the `/fabric` command to interact with Fabric patterns:

1. Type `/fabric` in the chat interface.
2. Select a pattern from the list provided.
3. Enter the input text for the selected pattern.
4. The AI will process your input using the chosen Fabric pattern and return the result.

## ğŸ“‚ File Structure

The project structure has been updated to include a comprehensive test suite:

```
AI_Functions/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ assemble.py
â”‚   â”‚   â”œâ”€â”€ banner.py
â”‚   â”‚   â”œâ”€â”€ basic_commands.py
â”‚   â”‚   â”œâ”€â”€ chunk_history.py
â”‚   â”‚   â”œâ”€â”€ ddg_search.py
â”‚   â”‚   â”œâ”€â”€ document_commands.py
â”‚   â”‚   â”œâ”€â”€ fabric_commands.py
â”‚   â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”‚   â”œâ”€â”€ input.py
â”‚   â”‚   â”œâ”€â”€ memory_commands.py
â”‚   â”‚   â”œâ”€â”€ memory_search.py
â”‚   â”‚   â”œâ”€â”€ ollama_client.py
â”‚   â”‚   â”œâ”€â”€ save_history.py
â”‚   â”‚   â””â”€â”€ slash_commands.py
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ test_file_utils.py
â”‚   â”‚   â”œâ”€â”€ test_input.py
â”‚   â”‚   â”œâ”€â”€ test_memory_search.py
â”‚   â”‚   â”œâ”€â”€ test_ollama_client.py
â”‚   â”‚   â””â”€â”€ test_save_history.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ assemble_module.md
â”‚   â”œâ”€â”€ banner_module.md
â”‚   â”œâ”€â”€ ddg_search_module.md
â”‚   â”œâ”€â”€ input_module.md
â”‚   â””â”€â”€ ollama_client.md
â”œâ”€â”€ documentation/
â”‚   â””â”€â”€ architecture_guide.md
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ¤ Contributing

Got ideas? We love them! ğŸ’¡ Submit a pull request or open an issue. Let's build the future of AI together!

## ğŸ“œ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

Built with â¤ï¸ and â˜• by the AI_Functions team. Let's make AI magic happen! âœ¨
