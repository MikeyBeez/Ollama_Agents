# AI_Functions: Your Personal AI Assistant Builder ğŸ¤–

Welcome to AI_Functions! This repository allows you to create a spectacular AI agent using Ollama. It's like having a LEGO set for AI - mix, match, and build your dream assistant! ğŸ§±âœ¨

## ğŸš€ What's New?

- ğŸ¨ Colorful command-line interface
- ğŸ§  Enhanced memory management
- ğŸ” Integrated DuckDuckGo search capabilities
- ğŸ› ï¸ Improved modular design for easy customization
- ğŸ” Memory search commands: `/ms` and `/msl`
- ğŸ§µ New `/fabric` command for using Fabric patterns
- ğŸ“‚ Refactored command structure for better organization
- ğŸ§ª Comprehensive test suite added

## ğŸŒŸ Key Features

1. ğŸ“š Modular Architecture: Each function is in a separate module, making it easy to add, remove, or modify features.
2. ğŸ’¬ Interactive CLI: Built with `prompt_toolkit` for a sci-fi movie-worthy experience!
3. ğŸ” Secure Configuration: Customize your AI's personality in `config.py`.
4. ğŸ§ª Comprehensive Testing: Because quality is our superpower!
5. ğŸŒ Web Search Integration: Your AI can now search the web using DuckDuckGo.
6. ğŸ“œ Chat History: Never forget a conversation with built-in history management.
7. ğŸ§  Memory Search: Quickly retrieve and utilize relevant information from past interactions and uploaded documents.
8. ğŸ§µ Fabric Integration: Use Fabric patterns for enhanced AI interactions.

## ğŸ› ï¸ Getting Started

### Prerequisites

- Python 3.8 or higher
- Conda (for managing virtual environments)
- Ollama (for running local language models)

### Setting Up the Environment

1. Fork and clone this repository:
   ```bash
   git clone https://github.com/yourusername/AI_Functions.git
   cd AI_Functions
   ```

2. Create and activate a conda virtual environment:
   ```bash
   conda create -n ai_functions python=3.8
   conda activate ai_functions
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Installing Ollama

1. Visit the [Ollama website](https://ollama.com/) and follow the installation instructions for your operating system.

2. Once installed, run Ollama and download a model (e.g., llama2):
   ```bash
   ollama run llama2
   ```

### Configuration

1. Customize your AI in `config.py`.

2. Set up your API keys and other configurations in a `.env` file (use `.env.example` as a template). Currently only Ollama is supported.

### Running the Application

Run the main script:
```bash
python src/main.py
```

## ğŸ§ª Running Tests

Ensure your AI is in top shape:

```bash
python -m unittest discover src/tests
```

## ğŸ“˜ Module Documentation

- ğŸ›ï¸ [Input Module](docs/input_module.md)
- ğŸ¤– [Ollama Client](docs/ollama_client.md)
- ğŸ§© [Assemble Module](docs/assemble_module.md)
- ğŸ¨ [Banner Module](docs/banner_module.md)
- ğŸ” [DuckDuckGo Search](docs/ddg_search_module.md)
- ğŸ—ï¸ [Architecture Guide](docs/architecture_guide.md)

## ğŸ” Memory Search Commands

- `/ms n m query`: Search memories and process query (short version, only shows answer)
- `/msl n m query`: Search memories and process query (long version, shows memories and answer)
  - `n`: Number of top results to retrieve
  - `m`: Minimum similarity threshold (0-1)
  - `query`: Your question or prompt
  Example: `/ms 5 0.7 Who was Alan Turing?`

## ğŸ§µ Fabric Command

Use the `/fabric` command to interact with Fabric patterns:

1. Type `/fabric` in the chat interface.
2. Select a pattern from the list provided.
3. Enter the input text for the selected pattern.
4. The AI will process your input using the chosen Fabric pattern and return the result.

## ğŸ“‚ File Structure

The project structure has been updated to include a comprehensive test suite and consolidated documentation:

```
AI_Functions/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ assemble.py
â”‚   â”‚   â”œâ”€â”€ banner.py
â”‚   â”‚   â”œâ”€â”€ basic_commands.py
â”‚   â”‚   â”œâ”€â”€ chunk_history.py
â”‚   â”‚   â”œâ”€â”€ ddg_search.py
â”‚   â”‚   â”œâ”€â”€ document_commands.py
â”‚   â”‚   â”œâ”€â”€ fabric_commands.py
â”‚   â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”‚   â”œâ”€â”€ input.py
â”‚   â”‚   â”œâ”€â”€ memory_commands.py
â”‚   â”‚   â”œâ”€â”€ memory_search.py
â”‚   â”‚   â”œâ”€â”€ ollama_client.py
â”‚   â”‚   â”œâ”€â”€ save_history.py
â”‚   â”‚   â””â”€â”€ slash_commands.py
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ test_file_utils.py
â”‚   â”‚   â”œâ”€â”€ test_input.py
â”‚   â”‚   â”œâ”€â”€ test_memory_search.py
â”‚   â”‚   â”œâ”€â”€ test_ollama_client.py
â”‚   â”‚   â””â”€â”€ test_save_history.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture_guide.md
â”‚   â”œâ”€â”€ assemble_module.md
â”‚   â”œâ”€â”€ banner_module.md
â”‚   â”œâ”€â”€ ddg_search_module.md
â”‚   â”œâ”€â”€ input_module.md
â”‚   â””â”€â”€ ollama_client.md
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## ğŸ“š Additional Documentation

To provide a deeper understanding of AI_Functions, we've expanded our documentation. These additional resources offer insights into the system's architecture, module interactions, and design principles.

### ğŸ—ï¸ Architecture Guide

For a comprehensive overview of AI_Functions' structure and design, refer to our [Architecture Guide](docs/architecture_guide.md). This document covers:

- ğŸ” High-level system overview
- ğŸ§© Detailed module descriptions and interactions
- ğŸ”„ Data flow through the system
- ğŸ› ï¸ Key design patterns and principles used
- ğŸš€ Scalability and future expansion considerations

The architecture guide is essential reading for developers looking to understand, modify, or extend AI_Functions.

### ğŸ§  Core Components

Detailed documentation for each core component is available:

- [Input Module](docs/input_module.md): Handles user input processing and command routing
- [Ollama Client](docs/ollama_client.md): Manages communication with the Ollama AI model
- [Memory Search](docs/memory_search.md): Implements advanced memory retrieval functionality
- [Document Processing](docs/document_processing.md): Covers document upload and chunking processes

### ğŸ› ï¸ Development Guides

For contributors and developers:

- [Setup Guide](docs/setup_guide.md): Detailed instructions for setting up the development environment
- [Testing Strategy](docs/testing_strategy.md): Overview of our testing approach and guidelines for writing tests
- [Contribution Guidelines](docs/contributing.md): How to contribute to AI_Functions effectively

### ğŸ”„ Workflow Diagrams

Visual representations of key processes:

- [User Interaction Workflow](docs/diagrams/user_interaction_workflow.png)
- [Memory Search Process](docs/diagrams/memory_search_process.png)
- [Document Upload and Processing](docs/diagrams/document_processing_workflow.png)

These diagrams provide a clear visual understanding of the system's operations.

### ğŸ“˜ API Documentation

For those integrating with AI_Functions:

- [API Reference](docs/api_reference.md): Detailed documentation of public APIs and integration points

### ğŸ”® Future Roadmap

Explore our plans for future development:

- [Roadmap](docs/roadmap.md): Upcoming features, improvements, and long-term vision for AI_Functions

We encourage all users, developers, and contributors to explore these resources. They are designed to provide a comprehensive understanding of AI_Functions, from high-level architecture to specific implementation details.
```

## ğŸ¤ Contributing

Got ideas? We love them! ğŸ’¡ Submit a pull request or open an issue. Let's build the future of AI together!

## ğŸ“œ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

Built with â¤ï¸ and â˜• by the AI_Functions team. Let's make AI magic happen! âœ¨
